# -*- coding: utf-8 -*-
"""heart-disease-predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L4iGYpGSBwgqqR2wA-FvvXJEdy6hwjbt
"""

# from google.colab import drive
# drive.mount('/content/drive')

# Regular EDA and plotting libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Commented out IPython magic to ensure Python compatibility.
# We want our plot to appear inside the notebook
# %matplotlib inline

# Models from Scikit-Learn
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier

# Model Evaluations
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.model_selection import RandomizedSearchCV,GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import roc_curve,plot_roc_curve

# Ignoring the warnings
import warnings
warnings.filterwarnings("ignore")

data = pd.read_csv("heart.csv")
data

"""# **Renaming Columns for better understanding**

"""

data.rename(columns={'age':'Age','sex':'Sex','cp':'Chest_pain','trestbps':'Resting_blood_pressure','chol':'Cholesterol','fbs':'Fasting_Blood_Sugar','restecg':'Resting_ECG','thalach':'Max_heart_rate_achieved','exang':'Exercise_induced_angina','oldpeak':'ST_depression_induced_by_exercise_relative_to_rest','slope':'Peak_exercise_ST_segment','ca':'Number_of_major_vessels_colored_by_fluoroscopy','thal':'Thalassemia_types','target':'Heart_disease'}, inplace=True)

data

"""# **Information about DATA**"""

data.info()
data.describe()

"""# **Correlation matrix & Matrix Visualisation**"""

data.corr()

# Matrix visualisation
corr_matrix=data.corr()
fig,ax=plt.subplots(figsize=(15,10))
ax=sns.heatmap(corr_matrix,annot=True,linewidths=0.5,fmt=".2f")

"""# **Target variable (Heart Disease-> 0(absence), 1(present))**"""

# Count 0 and 1
data['Heart_disease'].value_counts()

# Represent these in %age
countNoDisease = len(data[data.Heart_disease==0])
countHaveDisease = len(data[data.Heart_disease==1])
print("Percentage of patients not having Heart Disease: {:.2f}%".format((countNoDisease / (len(data.Heart_disease))*100)))
print("Percentage of patients having Heart Disease: {:.2f}%".format((countHaveDisease / (len(data.Heart_disease))*100)))

"""# **Heart Disease Frequency per Chest Pain Type**"""

# Relation of Heart disease with Chest Pain type
pd.crosstab(data['Chest_pain'],data['Heart_disease'])

# Visualisation
pd.crosstab(data['Chest_pain'],data['Heart_disease']).plot(kind='bar')
plt.title("Heart Disease Frequency per Chest Pain Type")
plt.xlabel("Chest Pain Types")
plt.ylabel("Amount")
plt.legend(['No disease','Disease'])
plt.xticks(rotation=0);

"""**Interpretation:**
The above plot shows frequency of each chest pain type for the population having and not having disease where type 0 is greater and where the population is more prone to not having disease

# **Resting Blood Pressure**
"""

data['Resting_blood_pressure'].plot(kind='kde')

"""**Interpretation:**
The above plot shows the density of Resting blood pressure and the maximum density is around 120-140

# **Heart Disease vs Fasting Blood Sugar**
"""

data['Fasting_Blood_Sugar'].value_counts()

# Comparision
pd.crosstab(data['Heart_disease'],data['Fasting_Blood_Sugar']).plot(kind="bar");
plt.title("Heart Disease Frequency vs Fasting Blood Sugar")
plt.xlabel("0 = No Disease , 1 = Disease")
plt.ylabel("Amount")
plt.legend(['0','1'])
plt.xticks(rotation=0);

"""**Interpretation:**
The above plot shows that the sugar level does not contribute to having or not having the heart disease

# **Heart Disease vs ECG Results**
"""

# Compare Heart disease with ECG Results
pd.crosstab(data['Heart_disease'],data['Resting_ECG'])

# Visualisation
pd.crosstab(data['Resting_ECG'],data['Heart_disease']).plot(kind="bar")
plt.title("Heart Disease Frequency per Resting_ECG")
plt.xlabel("ECG Result Types")
plt.ylabel("Amount")
plt.legend(['No disease','Disease'])
plt.xticks(rotation=0);

"""**Interpretation:**
The above plot shows frequency of each ECG type for the population having and not having disease where type 1 is greater and more prone to having disease

# **Heart Disease vs Thalassemia Types**
"""

# Visualisation
pd.crosstab(data['Thalassemia_types'],data['Heart_disease']).plot(kind="bar")
plt.title("Heart Disease Frequency per Thalassemia_types")
plt.xlabel("Thalassemia_types")
plt.ylabel("Amount")
plt.legend(['No disease','Disease'])
plt.xticks(rotation=0);

"""**Interpretation:**
The above plot shows frequency of each Thalassemia type for the population having and not having disease where type 2 is greater and is more prone to having disease

# **Modelling**

**Splitting data**
"""

X=data.drop('Heart_disease',axis=1)
y=data['Heart_disease']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

"""**1.Logistic Regression**"""

lr_model=LogisticRegression()
lr_model.fit(X_train,y_train)
# Training score
print("Training score of model is ",lr_model.score(X_train,y_train))
# Prediciton of the test variable
lr_model_y_preds=lr_model.predict(X_test)
# Testing Accuracy
print("Testing Accuracy is ",lr_model.score(X_test,y_test))

"""**Confusion Martix**"""

sns.set(font_scale=1.5)
def plot_conf_mat(y_test,y_preds):
  fig,ax=plt.subplots(figsize=(3,3))
  ax=sns.heatmap(confusion_matrix(y_test,y_preds),annot=True,cbar=False)
  plt.xlabel("True Label")
  plt.ylabel("Predicted Label")

plot_conf_mat(y_test,lr_model_y_preds)

print(classification_report(y_test,lr_model_y_preds))

"""**2. K-Nearest Neighbour**"""

knn=KNeighborsClassifier()
knn.fit(X_train,y_train)
# Training score
print("Training score of model is ",knn.score(X_train,y_train))
# Prediciton of the test variable
knn_y_preds=knn.predict(X_test)
# Testing Accuracy
print("Testing Accuracy is ",knn.score(X_test,y_test))

"""**Confusion Matrix**"""

sns.set(font_scale=1.5)
def plot_conf_mat(y_test,y_preds):
  fig,ax=plt.subplots(figsize=(3,3))
  ax=sns.heatmap(confusion_matrix(y_test,y_preds),annot=True,cbar=False)
  plt.xlabel("True Label")
  plt.ylabel("Predicted Label")

plot_conf_mat(y_test,knn_y_preds)

print(classification_report(y_test,knn_y_preds))

"""**3. Random Forest**"""

rf_model=RandomForestClassifier()
rf_model.fit(X_train,y_train)
# Training score
print("Training score of model is ",rf_model.score(X_train,y_train))
# Prediciton of the test variable
rf_model_y_preds=rf_model.predict(X_test)
# Testing Accuracy
print("Testing Accuracy is ",rf_model.score(X_test,y_test))

"""**Confusion Matrix**"""

sns.set(font_scale=1.5)
def plot_conf_mat(y_test,y_preds):
  fig,ax=plt.subplots(figsize=(3,3))
  ax=sns.heatmap(confusion_matrix(y_test,y_preds),annot=True,cbar=False)
  plt.xlabel("True Label")
  plt.ylabel("Predicted Label")

plot_conf_mat(y_test,rf_model_y_preds)

print(classification_report(y_test,rf_model_y_preds))

"""**4. Decision Tree**"""

dt_model=DecisionTreeClassifier()
dt_model.fit(X_train,y_train)
# Training score
print("Training score of model is ",dt_model.score(X_train,y_train))
# Prediciton of the test variable
dt_model_y_preds=dt_model.predict(X_test)
# Testing Accuracy
print("Testing Accuracy is ",dt_model.score(X_test,y_test))

"""**Confusion Matrix**"""

sns.set(font_scale=1.5)
def plot_conf_mat(y_test,y_preds):
  fig,ax=plt.subplots(figsize=(3,3))
  ax=sns.heatmap(confusion_matrix(y_test,y_preds),annot=True,cbar=False)
  plt.xlabel("True Label")
  plt.ylabel("Predicted Label")

plot_conf_mat(y_test,dt_model_y_preds)

print(classification_report(y_test,dt_model_y_preds))

"""#**Model Comparison based on Accuracy**"""

model_scores={'Logistic Regression':lr_model.score(X_test,y_test),
              'KNN':knn.score(X_test,y_test),
              'Random Forest':rf_model.score(X_test,y_test),
              'Decision Tree':dt_model.score(X_test,y_test)}
model_compare=pd.DataFrame(model_scores,index=['accuracy'])
model_compare

"""#**Selecting model:**
Based on the above analysis, Logistic Regression model is selected which got an accuracy of 89%.

**Feature Importance**
"""

lr_model.coef_

feature_dict=dict(zip(data.columns,list(lr_model.coef_[0])))
feature_dict

# Visualize feature importance
feature_data=pd.DataFrame(feature_dict,index=[0])
feature_data.T.plot(kind="bar",legend=False,title="Feature Importance")

"""**Saving the Model using pickle**"""

# We don't want our python program to run again-again whenever using our website, so we train the Reg_model once and
# import it somewhere else from where we can directly fetch it
# So we are dumping the Reg_model using Pickle into a file Model.pkl 
import pickle
pickle.dump(lr_model,open('LR_model2.pkl','wb'))
lr_model=pickle.load(open('LR_model2.pkl','rb'))

